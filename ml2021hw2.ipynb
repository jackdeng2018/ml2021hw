{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"ml2021hw2","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyOyFujBIk3BQhW4OTDs6e72"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"standard"},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cnA4qSWY4n6Z","executionInfo":{"status":"ok","timestamp":1661919551112,"user_tz":-480,"elapsed":311,"user":{"displayName":"邓晗","userId":"13890399823136089587"}},"outputId":"327ee810-3121-4de0-9916-f2168c30b4e4"},"outputs":[{"output_type":"stream","name":"stdout","text":["Wed Aug 31 04:19:10 2022       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   36C    P8     9W /  70W |      0MiB / 15109MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"]}],"source":["# gpu device type\n","!nvidia-smi"]},{"cell_type":"code","metadata":{"id":"jtClEMAMLVHw","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1661919551440,"user_tz":-480,"elapsed":5,"user":{"displayName":"邓晗","userId":"13890399823136089587"}},"outputId":"9f29822f-0020-4ea9-a127-5833f1cb0a94"},"source":["#@markdown <h3>← 输入了代码后运行以防止断开</h>\n","\n","\n","import IPython\n","from google.colab import output\n","\n","display(IPython.display.Javascript('''\n"," function ClickConnect(){\n","   btn = document.querySelector(\"colab-connect-button\")\n","   if (btn != null){\n","     console.log(\"Click colab-connect-button\"); \n","     btn.click() \n","     }\n","   \n","   btn = document.getElementById('ok')\n","   if (btn != null){\n","     console.log(\"Click reconnect\"); \n","     btn.click() \n","     }\n","  }\n","  \n","setInterval(ClickConnect,60000)\n","'''))\n","\n","print(\"Done.\")"],"execution_count":2,"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["\n"," function ClickConnect(){\n","   btn = document.querySelector(\"colab-connect-button\")\n","   if (btn != null){\n","     console.log(\"Click colab-connect-button\"); \n","     btn.click() \n","     }\n","   \n","   btn = document.getElementById('ok')\n","   if (btn != null){\n","     console.log(\"Click reconnect\"); \n","     btn.click() \n","     }\n","  }\n","  \n","setInterval(ClickConnect,60000)\n"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Done.\n"]}]},{"cell_type":"markdown","source":["## **Download Data**"],"metadata":{"id":"VZWDmsD85W-g"}},{"cell_type":"code","source":["!gdown --id '1HPkcmQmFGu-3OknddKIa5dNDsR05lIQR' --output data.zip\n","!unzip data.zip\n","!ls "],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6tZCB4Ul55wQ","executionInfo":{"status":"ok","timestamp":1661919586516,"user_tz":-480,"elapsed":35079,"user":{"displayName":"邓晗","userId":"13890399823136089587"}},"outputId":"522d848e-2c5b-4022-ff42-8b7b77d44bc7"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["/usr/local/lib/python3.7/dist-packages/gdown/cli.py:131: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n","  category=FutureWarning,\n","Downloading...\n","From: https://drive.google.com/uc?id=1HPkcmQmFGu-3OknddKIa5dNDsR05lIQR\n","To: /content/data.zip\n","100% 372M/372M [00:04<00:00, 93.1MB/s]\n","Archive:  data.zip\n","   creating: timit_11/\n","  inflating: timit_11/train_11.npy   \n","  inflating: timit_11/test_11.npy    \n","  inflating: timit_11/train_label_11.npy  \n","data.zip  sample_data  timit_11\n"]}]},{"cell_type":"markdown","source":["## **Prepare Data**"],"metadata":{"id":"3-BCI8DY6FI2"}},{"cell_type":"markdown","source":["Download data from google drive, then unzip it.\n","\n","You should have timit_11/train_11.npy, timit_11/train_label_11.npy, and timit_11/test_11.npy after running this block.\n","\n","timit_11/\n","\n","train_11.npy: training data\n","train_label_11.npy: training label\n","test_11.npy: testing data\n"],"metadata":{"id":"NHIGvCqYLIJm"}},{"cell_type":"code","source":["import numpy as np\n","\n","print('Loading data ...')\n","\n","data_root='./timit_11/'\n","train = np.load(data_root + 'train_11.npy')\n","train_label = np.load(data_root + 'train_label_11.npy')\n","test = np.load(data_root + 'test_11.npy')\n","\n","print('Size of training data: {}'.format(train.shape))\n","print('Size of testing data: {}'.format(test.shape))\n","\n","# print(train[:100, :100])\n","# print(train_label)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cdywVFqh6Liv","executionInfo":{"status":"ok","timestamp":1661924035618,"user_tz":-480,"elapsed":23317,"user":{"displayName":"邓晗","userId":"13890399823136089587"}},"outputId":"876f668c-6227-4f7a-9a6c-a9d6f1430b24"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Loading data ...\n","Size of training data: (1229932, 429)\n","Size of testing data: (451552, 429)\n"]}]},{"cell_type":"markdown","source":["## **Create Dataset**"],"metadata":{"id":"L04YRxuT6XM0"}},{"cell_type":"code","source":["import torch\n","from torch.utils.data import Dataset\n","\n","class TIMITDataset(Dataset):\n","  def __init__(self, X, y=None):\n","    self.data = torch.from_numpy(X).float()\n","    if y is not None:\n","      y = y.astype(np.int)\n","      self.label = torch.LongTensor(y)\n","    else:\n","      self.label = None\n","  \n","  def __getitem__(self, index):\n","    if self.label is not None:\n","      return self.data[index], self.label[index]\n","    else:\n","      return self.data[index]\n","\n","  def __len__(self):\n","    return len(self.data)\n"],"metadata":{"id":"I1LpsYDm6b6_","executionInfo":{"status":"ok","timestamp":1661924047170,"user_tz":-480,"elapsed":2805,"user":{"displayName":"邓晗","userId":"13890399823136089587"}}},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":["Split the labeled data into a training set and a validation set, you can modify the variable `VAL_RATIO` to change the ratio of validation data."],"metadata":{"id":"YM-yPqAA8eNX"}},{"cell_type":"code","source":["VAL_RATIO = 0.05\n","\n","percent = int(train.shape[0] * (1 - VAL_RATIO))\n","train_x, train_y, val_x, val_y = train[:percent], train_label[:percent], train[percent:], train_label[percent:]\n","print('Size of training set: {}'.format(train_x.shape))\n","print('Size of validation set: {}'.format(val_x.shape))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ytYsIqSx8mcp","executionInfo":{"status":"ok","timestamp":1661924057662,"user_tz":-480,"elapsed":376,"user":{"displayName":"邓晗","userId":"13890399823136089587"}},"outputId":"0e3c3040-c93e-4e78-b36e-8e39394ae113"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Size of training set: (1168435, 429)\n","Size of validation set: (61497, 429)\n"]}]},{"cell_type":"markdown","source":["Create a data loader from the dataset, feel free to tweak the variable `BATCH_SIZE` here."],"metadata":{"id":"s4-DsShm-Md9"}},{"cell_type":"code","source":["BATCH_SIZE = 1024\n","\n","from torch.utils.data import DataLoader\n","\n","train_set = TIMITDataset(train_x, train_y)\n","val_set = TIMITDataset(val_x, val_y)\n","train_loader = DataLoader(train_set, batch_size=BATCH_SIZE, shuffle=True) #only shuffle the training data\n","val_loader = DataLoader(val_set, batch_size=BATCH_SIZE, shuffle=False)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vVvubngu-NGl","executionInfo":{"status":"ok","timestamp":1661924065200,"user_tz":-480,"elapsed":2333,"user":{"displayName":"邓晗","userId":"13890399823136089587"}},"outputId":"dd17ca07-aa12-4a55-ec7f-4d83a5d609b2"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:8: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n","Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n","  \n"]}]},{"cell_type":"markdown","source":["Cleanup the unneeded variables to save memory.\n","\n","notes: if you need to use these variables later, then you may remove this block or clean up unneeded variables later\n","the data size is quite huge, so be aware of memory usage in colab"],"metadata":{"id":"5DPM3vrK-gIA"}},{"cell_type":"code","source":["import gc\n","\n","del train, train_label, train_x, train_y, val_x, val_y\n","gc.collect()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zoB0I2eh-hB1","executionInfo":{"status":"ok","timestamp":1661924070734,"user_tz":-480,"elapsed":373,"user":{"displayName":"邓晗","userId":"13890399823136089587"}},"outputId":"9c099dfc-7c3b-4565-9071-7bcb13abb1f3"},"execution_count":5,"outputs":[{"output_type":"execute_result","data":{"text/plain":["44"]},"metadata":{},"execution_count":5}]},{"cell_type":"markdown","source":["## **Create a Model**"],"metadata":{"id":"tTxrn_Z8-oaO"}},{"cell_type":"markdown","source":["### Greate outcome: RNN GRU"],"metadata":{"id":"hvPnfozIR7vO"}},{"cell_type":"code","source":["from torch.nn.modules import dropout\n","import torch\n","import torch.nn as nn\n","\n","class Classifier(nn.Module):\n","  def __init__(self):\n","    super(Classifier, self).__init__()\n","    self.lstm = nn.GRU(39, 256, 2, batch_first = True, dropout=0.25)\n","    self.classifier = nn.Sequential(\n","        # nn.Dropout,\n","        nn.Linear(11*256, 1024),\n","        nn.BatchNorm1d(1024),\n","        nn.ReLU(),\n","        nn.Dropout(),\n","        nn.Linear(1024, 39)\n","    )\n","    self.criterion = nn.CrossEntropyLoss()\n","\n","    # self.layer1 = nn.Linear(429, 1024)\n","    # self.layer2 = nn.Linear(1024, 512)\n","    # self.layer3 = nn.Linear(512, 128)\n","    # self.out = nn.Linear(128, 39) \n","    # self.act_fn = nn.Sigmoid()\n","  \n","  def forward(self, x):\n","    x = x.view(-1, 11, 39) # Cov1d卷积默认是对最后一层进行卷积\n","    x,_ = self.lstm(x)\n","    x = x.contiguous().view(x.size(0), -1) # batch size\n","    x = self.classifier(x) \n","\n","    # x = self.layer1(x)\n","    # x = self.act_fn(x)\n","\n","    # x = self.layer2(x)\n","    # x = self.act_fn(x)\n","\n","    # x = self.layer3(x)\n","    # x = self.act_fn(x)\n","\n","\n","    # x = self.out(x)\n","    return x"],"metadata":{"id":"92vi5fX6-tyd","executionInfo":{"status":"ok","timestamp":1661924085100,"user_tz":-480,"elapsed":392,"user":{"displayName":"邓晗","userId":"13890399823136089587"}}},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":["## **Training**"],"metadata":{"id":"TVecRLiG_ieL"}},{"cell_type":"code","source":["#check device\n","def get_device():\n","  return 'cuda' if torch.cuda.is_available() else 'cpu'"],"metadata":{"id":"lEwHVdGj_mUo","executionInfo":{"status":"ok","timestamp":1661924091388,"user_tz":-480,"elapsed":521,"user":{"displayName":"邓晗","userId":"13890399823136089587"}}},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":["Fix random seeds for reproducibility."],"metadata":{"id":"gnynQxvg_zHE"}},{"cell_type":"code","source":["# fix random seed\n","def same_seeds(seed):\n","    torch.manual_seed(seed)\n","    if torch.cuda.is_available():\n","        torch.cuda.manual_seed(seed)\n","        torch.cuda.manual_seed_all(seed)  \n","    np.random.seed(seed)  \n","    torch.backends.cudnn.benchmark = False\n","    torch.backends.cudnn.deterministic = True"],"metadata":{"id":"3ZgkPkwA_zrs","executionInfo":{"status":"ok","timestamp":1661924095112,"user_tz":-480,"elapsed":411,"user":{"displayName":"邓晗","userId":"13890399823136089587"}}},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":["## Config"],"metadata":{"id":"XNc2HSb7K70M"}},{"cell_type":"markdown","source":["Feel free to change the training parameters here."],"metadata":{"id":"yr9c3jHd_-zx"}},{"cell_type":"code","source":["from torch.optim.radam import RAdam\n","from re import VERBOSE\n","import math\n","\n","# fix random seed for reproducibility\n","same_seeds(0)\n","\n","# get device \n","device = get_device()\n","print(f'DEVICE: {device}')\n","\n","# training parameters\n","num_epoch = 50               # number of training epoch\n","learning_rate = 1e-4       # learning rate\n","# t = 10 # Warm up\n","# n_t = 0.5\n","# T = num_epoch\n","\n","# the path where checkpoint saved\n","model_path = './model.ckpt'\n","\n","# create model, define a loss function, and optimizer\n","model = Classifier().to(device)\n","criterion = nn.CrossEntropyLoss() \n","# optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n","optimizer = RAdam(model.parameters(), lr = learning_rate, weight_decay=1e-4)\n","\n","# learning rate scheduling\n","# lambda1 = lambda epoch: (0.9*epoch / t+0.1) if epoch < t else  0.1  if n_t * (1+math.cos(math.pi*(epoch - t)/(T-t)))<0.1 else n_t * (1+math.cos(math.pi*(epoch - t)/(T-t)))\n","# scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, T_0=30, VERBOSE = False)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9anQ3hr6__aR","executionInfo":{"status":"ok","timestamp":1661926324575,"user_tz":-480,"elapsed":434,"user":{"displayName":"邓晗","userId":"13890399823136089587"}},"outputId":"5aada3ca-1ef2-44de-ba50-89e561526b2e"},"execution_count":19,"outputs":[{"output_type":"stream","name":"stdout","text":["DEVICE: cuda\n"]}]},{"cell_type":"markdown","source":["Start training"],"metadata":{"id":"C38eq9IWAHNB"}},{"cell_type":"code","source":["from torch.optim import lr_scheduler\n","# start training\n","\n","best_acc = 0.0\n","for epoch in range(num_epoch):\n","    train_acc = 0.0\n","    train_loss = 0.0\n","    val_acc = 0.0\n","    val_loss = 0.0\n","\n","    # training\n","    model.train() # set the model to training mode\n","    \n","    # 学习率变化\n","    # scheduler.step()\n","\n","    for i, data in enumerate(train_loader):\n","        inputs, labels = data\n","        inputs, labels = inputs.to(device), labels.to(device)\n","        optimizer.zero_grad()\n","\n","        outputs = model(inputs) \n","        batch_loss = criterion(outputs, labels)\n","        _, train_pred = torch.max(outputs, 1) # get the index of the class with the highest probability\n","        batch_loss.backward() \n","        optimizer.step()\n","\n","        train_acc += (train_pred.cpu() == labels.cpu()).sum().item()\n","        train_loss += batch_loss.item()\n","\n","    # validation\n","    if len(val_set) > 0:\n","        model.eval() # set the model to evaluation mode\n","        with torch.no_grad():\n","            for i, data in enumerate(val_loader):\n","                inputs, labels = data\n","                inputs, labels = inputs.to(device), labels.to(device)\n","                outputs = model(inputs)\n","                batch_loss = criterion(outputs, labels) \n","                _, val_pred = torch.max(outputs, 1) \n","            \n","                val_acc += (val_pred.cpu() == labels.cpu()).sum().item() # get the index of the class with the highest probability\n","                val_loss += batch_loss.item()\n","\n","            print('[{:03d}/{:03d}] Train Acc: {:3.6f} Loss: {:3.6f} | Val Acc: {:3.6f} loss: {:3.6f}'.format(\n","                epoch + 1, num_epoch, train_acc/len(train_set), train_loss/len(train_loader), val_acc/len(val_set), val_loss/len(val_loader)\n","            ))\n","\n","            # if the model improves, save a checkpoint at this epoch\n","            if val_acc > best_acc:\n","                best_acc = val_acc\n","                torch.save(model.state_dict(), model_path)\n","                print('saving model with acc {:.3f}'.format(best_acc/len(val_set)))\n","    else:\n","        print('[{:03d}/{:03d}] Train Acc: {:3.6f} Loss: {:3.6f}'.format(\n","            epoch + 1, num_epoch, train_acc/len(train_set), train_loss/len(train_loader)\n","        ))\n","\n","# if not validating, save the last epoch\n","if len(val_set) == 0:\n","    torch.save(model.state_dict(), model_path)\n","    print('saving model at last epoch')\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TPI0cxO-AGKC","outputId":"528ccb00-0431-40b3-9c90-6831dd426947"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[001/050] Train Acc: 0.502220 Loss: 1.736911 | Val Acc: 0.615558 loss: 1.272668\n","saving model with acc 0.616\n"]}]},{"cell_type":"markdown","source":["## **Testing**"],"metadata":{"id":"FtJJd8HZA5KW"}},{"cell_type":"markdown","source":["Create a testing dataset, and load model from the saved checkpoint."],"metadata":{"id":"lbc1gkUgBCVk"}},{"cell_type":"code","source":["# create testing dataset\n","test_set = TIMITDataset(test, None)\n","test_loader = DataLoader(test_set, batch_size=BATCH_SIZE, shuffle=False)\n","\n","# create model and load weights from checkpoint\n","model = Classifier().to(device)\n","model.load_state_dict(torch.load(model_path))"],"metadata":{"id":"YQIegnJ6A9nH"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Make prediction."],"metadata":{"id":"lTOP0LVYBGR1"}},{"cell_type":"code","source":["predict = []\n","model.eval() # set the model to evaluation mode\n","with torch.no_grad():\n","    for i, data in enumerate(test_loader):\n","        inputs = data\n","        inputs = inputs.to(device)\n","        outputs = model(inputs)\n","        _, test_pred = torch.max(outputs, 1) # get the index of the class with the highest probability\n","\n","        for y in test_pred.cpu().numpy():\n","            predict.append(y)"],"metadata":{"id":"kxYqsDiABJOJ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Write prediction to a CSV file.\n","\n","After finish running this block, download the file `prediction.csv` from the files section on the left-hand side and submit it to Kaggle."],"metadata":{"id":"mzu4Q0aIBL0C"}},{"cell_type":"code","source":["with open('prediction.csv', 'w') as f:\n","    f.write('Id,Class\\n')\n","    for i, y in enumerate(predict):\n","        f.write('{},{}\\n'.format(i, y))"],"metadata":{"id":"DPpCo96YBPh1"},"execution_count":null,"outputs":[]}]}